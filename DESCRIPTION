Package: tok
Title: Fast Text Tokenization
Version: 0.1.0
Authors@R: c(
    person("Daniel", "Falbel", , "daniel@posit.co", c("aut", "cre")),
    person(family = "Posit", role = c("cph"))
  )
Description:
  Interfaces with the 'HuggingFace' tokenizers library to provide implementations
  of today's most used tokenizers such as the 'Byte-Pair Encoding' algorithm. It's
  extremely fast for both training new vocabularies and tokenizing texts.
License: MIT + file LICENSE
SystemRequirements: Rust tool chain w/ cargo, libclang/llvm-config
Encoding: UTF-8
LazyData: true
Roxygen: list(markdown = TRUE)
RoxygenNote: 7.2.3
Imports:
    R6,
    openssl
Suggests:
    rmarkdown,
    testthat (>= 3.0.0)
Config/testthat/edition: 3
